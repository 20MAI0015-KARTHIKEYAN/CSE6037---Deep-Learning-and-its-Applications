{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intE7zPXIj0f"
   },
   "source": [
    "20MAI0015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9rj-EgEH93O"
   },
   "source": [
    "GITHUB\n",
    "\n",
    "ACTIVITY 1 - \n",
    "Activity 2 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nf3TR336ICQb"
   },
   "source": [
    "# ALEXNET - ACTIVITY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gx23yzsfgc89"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBaXLovAjXUN",
    "outputId": "abf8a6eb-b915-4e3b-b596-183643566c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,730,506\n",
      "Trainable params: 25,709,350\n",
      "Non-trainable params: 21,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.4))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(10))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHAlc3Zijc8m"
   },
   "outputs": [],
   "source": [
    "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras library for CIFAR dataset\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train),(x_test, y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-validation-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSOB-hZljgds",
    "outputId": "c83c454d-4923-4fc9-a783-53be81fad201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((35000, 32, 32, 3), (35000, 1))\n",
      "((15000, 32, 32, 3), (15000, 1))\n",
      "((10000, 32, 32, 3), (10000, 1))\n"
     ]
    }
   ],
   "source": [
    "#Dimension of the CIFAR10 dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onehot Encoding the labels.\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
    "y_train=to_categorical(y_train)\n",
    "y_val=to_categorical(y_val)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVGlxoZnjxwP",
    "outputId": "a35e158d-77ac-4210-d04e-70ac8f1960a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((35000, 32, 32, 3), (35000, 10))\n",
      "((15000, 32, 32, 3), (15000, 10))\n",
      "((10000, 32, 32, 3), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "#Verifying the dimension after one hot encoding\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameters\n",
    "batch_size= 100\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJpZD65aj70p",
    "outputId": "3a7d9696-96fe-41e2-dd0c-2c7bde857a0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "350/350 [==============================] - 42s 24ms/step - loss: 1.8080 - accuracy: 0.3438 - val_loss: 1.7722 - val_accuracy: 0.3774\n",
      "Epoch 2/50\n",
      "350/350 [==============================] - 8s 22ms/step - loss: 1.3926 - accuracy: 0.5130 - val_loss: 1.8843 - val_accuracy: 0.3698\n",
      "Epoch 3/50\n",
      "350/350 [==============================] - 8s 22ms/step - loss: 1.2389 - accuracy: 0.5735 - val_loss: 1.7056 - val_accuracy: 0.4299\n",
      "Epoch 4/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 1.1210 - accuracy: 0.6158 - val_loss: 1.6365 - val_accuracy: 0.4638\n",
      "Epoch 5/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 1.0249 - accuracy: 0.6475 - val_loss: 1.6272 - val_accuracy: 0.4573\n",
      "Epoch 6/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.9313 - accuracy: 0.6851 - val_loss: 1.7104 - val_accuracy: 0.4515\n",
      "Epoch 7/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.8451 - accuracy: 0.7170 - val_loss: 2.1341 - val_accuracy: 0.3637\n",
      "Epoch 8/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.7466 - accuracy: 0.7521 - val_loss: 1.6017 - val_accuracy: 0.5147\n",
      "Epoch 9/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.6711 - accuracy: 0.7806 - val_loss: 1.5265 - val_accuracy: 0.5128\n",
      "Epoch 10/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.5841 - accuracy: 0.8105 - val_loss: 1.2180 - val_accuracy: 0.5904\n",
      "Epoch 11/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.5221 - accuracy: 0.8330 - val_loss: 2.0115 - val_accuracy: 0.4500\n",
      "Epoch 12/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.4389 - accuracy: 0.8628 - val_loss: 1.8165 - val_accuracy: 0.4777\n",
      "Epoch 13/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.3804 - accuracy: 0.8805 - val_loss: 1.6511 - val_accuracy: 0.5199\n",
      "Epoch 14/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.3318 - accuracy: 0.8960 - val_loss: 1.7085 - val_accuracy: 0.5173\n",
      "Epoch 15/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.2931 - accuracy: 0.9086 - val_loss: 1.6255 - val_accuracy: 0.5311\n",
      "Epoch 16/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.2606 - accuracy: 0.9210 - val_loss: 1.9673 - val_accuracy: 0.4869\n",
      "Epoch 17/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.2331 - accuracy: 0.9288 - val_loss: 1.6853 - val_accuracy: 0.5351\n",
      "Epoch 18/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1991 - accuracy: 0.9390 - val_loss: 1.7146 - val_accuracy: 0.5532\n",
      "Epoch 19/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1931 - accuracy: 0.9421 - val_loss: 2.1930 - val_accuracy: 0.4502\n",
      "Epoch 20/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1702 - accuracy: 0.9490 - val_loss: 1.7797 - val_accuracy: 0.5393\n",
      "Epoch 21/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1548 - accuracy: 0.9540 - val_loss: 1.5179 - val_accuracy: 0.5881\n",
      "Epoch 22/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1621 - accuracy: 0.9495 - val_loss: 2.9185 - val_accuracy: 0.3559\n",
      "Epoch 23/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1325 - accuracy: 0.9595 - val_loss: 1.8316 - val_accuracy: 0.5433\n",
      "Epoch 24/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1285 - accuracy: 0.9612 - val_loss: 1.7517 - val_accuracy: 0.5627\n",
      "Epoch 25/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1157 - accuracy: 0.9654 - val_loss: 1.8696 - val_accuracy: 0.5326\n",
      "Epoch 26/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1140 - accuracy: 0.9645 - val_loss: 1.6810 - val_accuracy: 0.5729\n",
      "Epoch 27/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1102 - accuracy: 0.9657 - val_loss: 1.9152 - val_accuracy: 0.5260\n",
      "Epoch 28/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.1112 - accuracy: 0.9645 - val_loss: 1.9260 - val_accuracy: 0.5493\n",
      "Epoch 29/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0911 - accuracy: 0.9723 - val_loss: 1.6320 - val_accuracy: 0.5889\n",
      "Epoch 30/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0901 - accuracy: 0.9741 - val_loss: 2.2455 - val_accuracy: 0.4894\n",
      "Epoch 31/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0870 - accuracy: 0.9738 - val_loss: 2.6042 - val_accuracy: 0.4596\n",
      "Epoch 32/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0817 - accuracy: 0.9759 - val_loss: 1.9293 - val_accuracy: 0.5351\n",
      "Epoch 33/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0880 - accuracy: 0.9720 - val_loss: 1.8548 - val_accuracy: 0.5462\n",
      "Epoch 34/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0838 - accuracy: 0.9749 - val_loss: 2.1725 - val_accuracy: 0.5299\n",
      "Epoch 35/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0781 - accuracy: 0.9760 - val_loss: 1.8598 - val_accuracy: 0.5745\n",
      "Epoch 36/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0752 - accuracy: 0.9785 - val_loss: 1.7656 - val_accuracy: 0.5749\n",
      "Epoch 37/50\n",
      "350/350 [==============================] - 8s 24ms/step - loss: 0.0676 - accuracy: 0.9793 - val_loss: 2.3372 - val_accuracy: 0.5158\n",
      "Epoch 38/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0693 - accuracy: 0.9791 - val_loss: 2.3605 - val_accuracy: 0.5066\n",
      "Epoch 39/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0770 - accuracy: 0.9750 - val_loss: 1.9521 - val_accuracy: 0.5458\n",
      "Epoch 40/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0718 - accuracy: 0.9765 - val_loss: 2.7653 - val_accuracy: 0.4399\n",
      "Epoch 41/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 2.6678 - val_accuracy: 0.4703\n",
      "Epoch 42/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0660 - accuracy: 0.9788 - val_loss: 2.3610 - val_accuracy: 0.5244\n",
      "Epoch 43/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0584 - accuracy: 0.9829 - val_loss: 2.1413 - val_accuracy: 0.5367\n",
      "Epoch 44/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 1.8736 - val_accuracy: 0.5902\n",
      "Epoch 45/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0564 - accuracy: 0.9822 - val_loss: 1.6111 - val_accuracy: 0.6150\n",
      "Epoch 46/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0439 - accuracy: 0.9864 - val_loss: 3.3836 - val_accuracy: 0.3925\n",
      "Epoch 47/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 2.4434 - val_accuracy: 0.4805\n",
      "Epoch 48/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0478 - accuracy: 0.9856 - val_loss: 2.5908 - val_accuracy: 0.4985\n",
      "Epoch 49/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0510 - accuracy: 0.9835 - val_loss: 2.0694 - val_accuracy: 0.5369\n",
      "Epoch 50/50\n",
      "350/350 [==============================] - 8s 23ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 2.2316 - val_accuracy: 0.5373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff368cc0d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "AlexNet.fit(x_train, y_train,\n",
    "batch_size=batch_size,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37VADLlklGR5",
    "outputId": "a0898b35-ed67-4b14-eb29-ee82ac97993a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 2.2175 - accuracy: 0.5383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.217454433441162, 0.5382999777793884]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AlexNet.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F55TZx1piI7"
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "AlexNet.save('saved_model/AlexNetModel.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da7ly_ARHlzT"
   },
   "source": [
    "TRANSFER LEARNING IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3PU1ylFqKNo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv3TztjAqKQE"
   },
   "outputs": [],
   "source": [
    "Base_model = tf.keras.models.load_model('saved_model/AlexNetModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,Y_train), (X_valid, Y_valid) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand new axis, channel axis \n",
    "X_train = np.expand_dims(X_train, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional]: we may need 3 channel (instead of 1)\n",
    "X_train = np.repeat(X_train, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's always better to normalize \n",
    "X_train = X_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "X_train = tf.image.resize(X_train, [32,32]) # if we want to resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.expand_dims(X_valid, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional]: we may need 3 channel (instead of 1)\n",
    "X_valid = np.repeat(X_valid, 3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's always better to normalize \n",
    "X_valid = X_valid.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
    "X_valid = tf.image.resize(X_valid, [32,32]) # if we want to resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(Y_train[:nb_train_samples], num_classes)\n",
    "Y_valid = np_utils.to_categorical(Y_valid[:nb_valid_samples], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BpG02VKNFK15",
    "outputId": "2dd7de12-2cf7-4476-d133-0a76b5193843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "(TensorShape([60000, 32, 32, 3]), (60000, 10))\n",
      "(TensorShape([10000, 32, 32, 3]), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print((X_train.shape,Y_train.shape))\n",
    "print((X_valid.shape,Y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4xSGmWMrpox"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model(\"saved_model/AlexNetModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QiflHqmFwjNb",
    "outputId": "c373361b-82a3-4180-b545-ae7deb456bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 25,730,506\n",
      "Trainable params: 25,709,350\n",
      "Non-trainable params: 21,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.trainable=False\n",
    "model = tf.keras.Sequential([\n",
    "    new_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUA4NP8tARvp",
    "outputId": "0107638c-ff46-4ad2-d64c-7389cbc348d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 10)                25730506  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 25,730,616\n",
      "Trainable params: 110\n",
      "Non-trainable params: 25,730,506\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dBpwyrO21TRe",
    "outputId": "340cc730-38ab-4637-b510-eac6069ede2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1123 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1122 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 5s 9ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=batch_size,\n",
    "epochs=10,\n",
    "verbose=1,\n",
    "validation_data=(X_valid, Y_valid))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "AlexNet-TransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
